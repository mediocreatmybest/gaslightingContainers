{"cells":[{"cell_type":"markdown","metadata":{"id":"gd-vX3cavOCt"},"source":["# **Stable Diffusion fine-tuning**\n","Fine-tunes diffusers Stable Diffusion"]},{"cell_type":"markdown","metadata":{"id":"QYOlvQ1nQL7c"},"source":["### Setup"]},{"cell_type":"markdown","metadata":{"id":"ghD5JwoJWh1V"},"source":["Test Nvidia GPU is working."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1295,"status":"ok","timestamp":1670229092260,"user":{"displayName":"Rippy Au","userId":"15617253756430269211"},"user_tz":-570},"id":"23TOba33L4qf","outputId":"966734ad-a22a-4b3a-af90-aa53a2d6bf53"},"outputs":[],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"markdown","metadata":{"id":"Qma8xR_YWfYg"},"source":["Mount Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47057,"status":"ok","timestamp":1670229155677,"user":{"displayName":"Rippy Au","userId":"15617253756430269211"},"user_tz":-570},"id":"xS8UkNCdfjhj","outputId":"31b46e38-e63e-4e99-f41b-1307ed80ad2b"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":87789,"status":"ok","timestamp":1670229243461,"user":{"displayName":"Rippy Au","userId":"15617253756430269211"},"user_tz":-570},"id":"aIrgth7sqFML","outputId":"a2a7488f-71ad-40cd-9bee-a36ca1001df4"},"outputs":[],"source":["#@title Install dependencies\n","!pip install diffusers accelerate bitsandbytes torch-ema\n","!pip install transformers scipy ftfy \"ipywidgets>=7,<8\"\n","!pip install deepspeed triton mpi4py"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"1Fcyyt0daU4e"},"source":["Model license needs to be accepted to access weights via git / huggingface."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8TRAh8G6sNfA"},"outputs":[],"source":["from google.colab import output\n","output.enable_custom_widget_manager()\n","from huggingface_hub import notebook_login\n","notebook_login()\n","#Is this needed? I don't think so."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p4wj_txjP3TC"},"outputs":[],"source":["import os\n","from IPython.display import clear_output\n","import time\n","\n","#@markdown # Model Download\n","Model_Version = \"1.5\" #@param [\"1.5\", \"1.5\"]\n","\n","token = \"\" #@param {type:\"string\"}\n","\n","if token==\"\":\n","  token=input(\"Insert your huggingface token :\")\n","  %cd /content/gdrive/MyDrive/sd/\n","  clear_output()\n","!git init\n","!git lfs install --system --skip-repo\n","!git clone --branch main \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\" \"/content/gdrive/MyDrive/sd/stable-diffusion-v1-5\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yzskQjwibald"},"outputs":[],"source":["#@markdown # Update SD 1.5\n","Update_repo = True #@param {type:\"boolean\"}\n","if Update_repo:\n","  %cd /content/gdrive/MyDrive/sd/stable-diffusion-v1-5/\n","  print('\u001b[1;32m')\n","  !git pull"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mtcn7fIhXvfz"},"outputs":[],"source":["#@markdown Force git to update if it won't update\n","Force_git = False #@param {type: \"boolean\"}\n","if Force_git:\n","  %cd /content/gdrive/MyDrive/sd/stable-diffusion-v1-5/\n","  print('\u001b[1;32m')\n","  !git reset --hard HEAD\n","  !git pull"]},{"cell_type":"markdown","metadata":{"id":"WpbkRVOocWs3"},"source":["Git LFS if you didn't need to clone"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":543851,"status":"ok","timestamp":1670230189840,"user":{"displayName":"Rippy Au","userId":"15617253756430269211"},"user_tz":-570},"id":"twvPqpZab7kL","outputId":"16b557df-b3f1-4870-e3a4-7582c77cbb2b"},"outputs":[],"source":["%cd /content/gdrive/MyDrive/sd/stable-diffusion-v1-5/\n","!git init\n","!git lfs install --system --skip-repo\n","!git lfs pull"]},{"cell_type":"code","execution_count":7,"metadata":{"cellView":"form","executionInfo":{"elapsed":65996,"status":"ok","timestamp":1670230814364,"user":{"displayName":"Rippy Au","userId":"15617253756430269211"},"user_tz":-570},"id":"xSKWBKFPArKS"},"outputs":[],"source":["#@title Model loading\n","import torch\n","from diffusers import StableDiffusionPipeline\n","pipe = StableDiffusionPipeline.from_pretrained(\"/content/gdrive/MyDrive/sd/stable-diffusion-v1-5\",\n","                                               # revision=\"fp16\", torch_dtype=torch.float16,\n","                                               torch_dtype=torch.float32)  # bfloat16,\n","pipe = pipe.to(\"cuda\")\n","# pipe.scheduler.set_timesteps(1000)  # TODO\n","del pipe.safety_checker\n","pipe.safety_checker = lambda clip_input, images: (images, [False for _ in images])  # Is this needed still?  "]},{"cell_type":"markdown","metadata":{"id":"IpuAUvLCkMhF"},"source":["### Load dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"LA9myHTxbDhm"},"outputs":[],"source":["#@title Load dataset\n","#@markdown - Upload a zip file\n","#@markdown - file names are prompts\n","#@markdown - If you leave the dataset_link blank, colab will give you an upload button instead.\n","#@markdown - Alternatively you can provide a csv file with the prompt for each image in the desc_link or desc_filename section.\n","import requests.exceptions\n","dataset_link = \"\"  #@param {type: \"string\", allow-input: true} [\"\", \"https://drive.google.com/uc?id=17bPt7G3N_vGKCCxppIOPbPlhv1qUnv0o\", \"https://drive.google.com/uc?id=1p4xwKEDHPhm18zBS_pMVJ1mp2Y5CE1a8\"]\n","desc_link = \"\"  #@param {type: \"string\", allow-input: true} [\"\", \"https://drive.google.com/uc?id=1iSDbibP-o9gIk9YzpmI-Y_h_uWPqxTZh\"]\n","desc_filename = \"\"  #@param {type: \"string\", allow-input: true} [\"\", \"desc.csv\"]\n","no_prompt = False  #@param {type: \"boolean\"}\n","\n","\n","try:\n","    import gdown\n","    gdown.download(dataset_link)\n","except requests.exceptions.MissingSchema:\n","    from google.colab import files\n","    print(\"Upload dataset:\")\n","    uploaded = list(files.upload())\n","    if True:\n","        path = uploaded[0]\n","    else:\n","        print(\"Please upload something. Erroring out soon...\")\n","    !mv {path} dataset.zip\n","!unzip -q -o -d data dataset.zip\n","from PIL import Image\n","\n","\n","def check_image(path):\n","    try:\n","        Image.open(path)\n","        return True\n","    except:\n","        return False\n","\n","import os\n","import glob\n","# import shutil\n","imgs = [f for f in glob.glob(\"data/**\", recursive=True) if os.path.isfile(f) and check_image(f)]\n","stemns = {os.path.basename(img): img for img in imgs}\n","# for k, v in stemns.items():\n","#     k2 = k.replace(\"jpeg\", \"jpg\").replace(\"JPG\", \"jpg\")  # ???\n","#     stemns[k2] = v\n","\n","try:\n","    gdown.download(desc_link, \"desc.csv\")\n","except requests.exceptions.MissingSchema:\n","    pass\n","  \n","\n","if no_prompt:\n","    titles = [\"\" for img in imgs]\n","elif os.path.exists(\"desc.csv\"):\n","    import pandas as pd\n","    captions = pd.read_csv(\"desc.csv\")\n","    imgs, titles = zip(*[\n","        (stemns[name], caption)\n","        for *_, name, caption in captions.itertuples()\n","        if name in stemns])\n","else:\n","    from pathlib import Path\n","    titles = [Path(img).stem for img in imgs]"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"3giu6cgfzjmB"},"outputs":[],"source":["from torchvision import transforms as TF\n","from PIL import Image\n","import random\n","\n","#@markdown This will resize, then display the first 20 images in your dataset.\n","class Text2ImageDataset(torch.utils.data.Dataset):\n","    def __init__(self, texts, images, resize=False, flip=False, cfg_prob=0.0):\n","        super().__init__()\n","        self.texts = texts\n","        self.images = images\n","        self.transform = TF.Compose([\n","            TF.Resize(512),\n","            TF.Resize((512, 512)) if resize else TF.CenterCrop(512),\n","        ] + ([TF.RandomHorizontalFlip()] if flip else []) + [\n","            TF.ToTensor(),\n","            TF.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n","        ])\n","        self.cfg_prob = cfg_prob\n","    \n","    def __len__(self):\n","        assert len(self.texts) == len(self.images)\n","        return len(self.texts)\n","    \n","    def __getitem__(self, idx):\n","        img = self.images[idx]\n","        img = Image.open(img).convert(\"RGB\")\n","        text = self.texts[idx] if random.random() > self.cfg_prob else \"\"\n","        return (self.texts[idx], self.transform(img))\n","\n","\n","flip = False #@param {type: \"boolean\"}\n","resize = True  #@param {type: \"boolean\"}\n","cfg_prob = 0.2  #@param {type: \"number\"}\n","\n","dataset = Text2ImageDataset(titles, imgs, resize=resize, flip=flip,\n","                            cfg_prob=cfg_prob)\n","\n","def show(x):\n","    return Image.fromarray(((x.permute(1, 2, 0).numpy() / 2 + 0.5) * 255).astype(\"uint8\")).convert(\"RGB\").resize((128, 128))\n","\n","\n","def image_grid(imgs, rows, cols):\n","    # assert len(imgs) == rows*cols\n","\n","    w, h = imgs[0].size\n","    grid = Image.new(\"RGB\", size=(cols*w, rows*h))\n","    grid_w, grid_h = grid.size\n","    \n","    for i, img in enumerate(imgs):\n","        grid.paste(img, box=(i%cols*w, i//cols*h))\n","    return grid\n","\n","\n","num_images = 20  #@param {type: \"integer\"}\n","cols = 7  #@param {type: \"integer\"}\n","pics = [show(i) for _, (t, i) in zip(range(num_images), dataset)]\n","image_grid(pics, (len(pics) - 1) // cols + 1, cols)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bjq28s5BASMF"},"outputs":[],"source":["train_size = 0.8  #@param {type: \"number\"}\n","train_len = int(len(dataset) * train_size)\n","train_ds, test_ds = torch.utils.data.random_split(dataset, [train_len, len(dataset) - train_len])"]},{"cell_type":"markdown","metadata":{"id":"HJZUEqhP-Spx"},"source":["### Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"brKu--wg-OPs"},"outputs":[],"source":["#@title Create dataloader\n","# not today old friend\n","# from accelerate import Accelerator\n","# accelerator = Accelerator(gradient_accumulation_steps=grad_acc)\n","train_bs = 1  #@param {type: \"integer\"}\n","test_bs = 1  #@param {type: \"integer\"}\n","train_dl, test_dl = (torch.utils.data.DataLoader(train_ds, batch_size=train_bs, shuffle=True, num_workers=0),\n","                     torch.utils.data.DataLoader(test_ds, batch_size=test_bs, shuffle=True, num_workers=0))"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"n0ZI_DLC-99c"},"outputs":[],"source":["#@title Prepare optimizer\n","from itertools import chain\n","from transformers import get_scheduler\n","from torch_ema import ExponentialMovingAverage\n","\n","\n","train_steps = 500  #@param {type: \"integer\"}\n","warmup = 48  #@param {type: \"integer\"}\n","grad_acc = 4  #@param {type: \"integer\"}\n","\n","lr = 1e-3  #@param {type: \"number\"}\n","wd = 1e-5  #@param {type: \"number\"}\n","ema_decay = 0.0  #@param {type: \"number\"}\n","scheduler_type = \"linear\" #@param {type: \"string\"} [\"cosine\", \"constant\", \"constant_with_warmup\", \"linear\"]\n","pipe.text_encoder.requires_grad_(False)\n","pipe.unet.requires_grad_(False)\n","pipe.vae.requires_grad_(False)\n","#@markdown \"Text\" gives slightly better results. Equivalent to prompt tuning when\n","#@markdown `no_prompt` is checked.\n","to_tune = \"text\"  #@param {type: \"string\"} [\"text\", \"unet\", \"FULL\"]\n","model = (\n","    pipe.unet\n","        if to_tune == \"unet\"\n","    else torch.nn.ModuleList([pipe.unet, pipe.text_encoder])\n","        if to_tune == \"full\"\n","    else pipe.text_encoder\n","        if to_tune == \"text\"\n","    else 1/0)\n","# model = torch.nn.ModuleList([pipe.unet, pipe.text_encoder])\n","pipe.guidance_scale = 1.0 # Haha\n","# TODO\n","# \"token_embedding\" or \"position_embedding\"  # ?\n","condition = lambda x: (\n","    (\"norm\" in x or \"bias\" in x or \"emb\" in x or \"attn\" in x)\n","    if to_tune in (\"unet\", \"full\") else True)  # \"token_embedding\" in x  # \"norm\" in x or \"bias\" in x or \"emb\" in x  # or \"transformer\" in x  # True  # TODO\n","params = [y for x, y in model.named_parameters() if condition(x)]\n","for param in params:\n","    param.requires_grad_(True)\n","print(\"Tunable parameters:\", sum([x.numel() for x in params]))\n","adam_kwargs = dict(lr=lr, weight_decay=wd, betas=(0.9, 0.99), eps=1e-8)\n","# import bitsandbytes as bnb\n","# optimizer = bnb.optim.Adam8bit(params, lr=lr, weight_decay=wd)\n","from argparse import Namespace\n","import deepspeed\n","_, optimizer, *_ = deepspeed.initialize(args=Namespace(**{}), model=model, model_parameters=params, config={\n","    \"optimizer\": {\n","        \"type\": \"Adam\",\n","        \"params\": adam_kwargs\n","    },\n","    \"offload_optimizer\": \"cpu\",\n","    \"train_batch_size\": train_bs\n","})\n","# optimizer = torch.optim.AdamW(params, **adam_kwargs)\n","# optimizer = torch.optim.SGD(params, lr=lr * 100, weight_decay=wd)\n","if ema_decay > 0:\n","    ema = ExponentialMovingAverage(params, decay=ema_decay)\n","else:\n","    from argparse import Namespace\n","    ema = Namespace(average_parameters=lambda: open(\"/tmp/dontusethisplease\", \"w\"),\n","                    update=lambda: None)\n","scheduler = get_scheduler(scheduler_type, optimizer, warmup,\n","                          train_steps // grad_acc)\n","# scaler = torch.cuda.amp.GradScaler()\n","global_i = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kb0tH7BuYkhk"},"outputs":[],"source":["#@title Update scheduler\n","from diffusers import DDPMScheduler\n","ps = pipe.scheduler\n","train_scheduler = ps  # DDPMScheduler(1000, ps.beta_start, ps.beta_end, \"scaled_linear\")  # ps.beta_schedule)\n","# train_scheduler = DDPMScheduler(\n","    # beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000, tensor_format=\"pt\")\n","ps.beta_start = 0.00085\n","ps.beta_end = 0.012\n","ps.beta_schedule = \"scaled_linear\"  # pipe.encode_images()\n","ps.set_timesteps(1000)  # TODO"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6979,"status":"ok","timestamp":1667221524053,"user":{"displayName":"Rippy Au","userId":"15617253756430269211"},"user_tz":-570},"id":"LxBF5M--iKW3","outputId":"26fe2858-781c-47c1-953d-464ac56220f4"},"outputs":[],"source":["#@title Set seed\n","#@markdown 0 for random seed\n","from transformers import set_seed\n","import random\n","seed = 0  #@param {type: \"integer\"}\n","\n","if seed == 0:\n","    seed = random.getrandbits(16)\n","\n","print(\"Using seed:\", seed)\n","set_seed(seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4129,"status":"ok","timestamp":1667221528179,"user":{"displayName":"Rippy Au","userId":"15617253756430269211"},"user_tz":-570},"id":"eRZJCL12howb","outputId":"14141176-4ca3-4dec-cb91-0e9dc131918c"},"outputs":[],"source":["!pip install tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"u7S_SadBD-X4"},"outputs":[],"source":["#@title Fine-tuning\n","from IPython.display import display, clear_output\n","from ipywidgets import Output\n","import shutil\n","import gc\n","from tqdm import trange, tqdm\n","\n","\n","def get_loss(x, y):\n","    assert len(x) == len(y)\n","    bs = len(x)\n","    t = torch.randint(0, len(ts), (bs,)).long()\n","    t = ts[t]\n","    toks = pipe.tokenizer(x, padding=True)\n","    device = \"cuda\"\n","    dtype = torch.FloatTensor\n","    if True:  # with torch.autocast(\"cuda\"):\n","        with torch.inference_mode():\n","            latent_model_input = pipe.vae.encode(y.type(dtype).to(device)).latent_dist.sample().cpu() * 0.18215\n","            noise = torch.randn_like(latent_model_input)\n","            noised = train_scheduler.add_noise(latent_model_input, noise, t)\n","        torch.set_grad_enabled(any(x.requires_grad for x in pipe.text_encoder.parameters()))\n","        text_embeddings = pipe.text_encoder(torch.LongTensor(toks.input_ids).to(device),\n","                                                attention_mask=torch.tensor(toks.attention_mask).type(dtype).to(device))[0]\n","        torch.set_grad_enabled(True)\n","        eps = pipe.unet(noised.to(device), t.long().to(device), encoder_hidden_states=text_embeddings)[\"sample\"]\n","        loss = torch.nn.functional.mse_loss(noise.to(device), eps, reduction=\"none\").mean([1, 2, 3]).mean()  # )\n","    return loss\n","\n","\n","def get_sd():\n","    return {k: v for k, v in model.named_parameters() if v.requires_grad}\n","\n","\n","ts = torch.LongTensor(train_scheduler.timesteps)\n","losses = []\n","generate_every = 50  #@param {type: \"integer\"}\n","n_generate = 1  #@param {type: \"integer\"}\n","save_every = 200  #@param {type: \"integer\"}\n","save_verbose = False  #@param {type: \"boolean\"}\n","bar = tqdm(initial=global_i, total=train_steps)\n","try:\n","    while True:\n","        print(\"Training...\")\n","        total_loss = 0.0\n","        for i, (x, y) in enumerate(train_dl):\n","            model.train()\n","            gc.collect()\n","            torch.cuda.empty_cache()\n","            loss = get_loss(x, y)\n","            losses.append(loss.item())\n","            total_loss += loss.item()\n","            bar.set_postfix(loss=total_loss/(i + 1))\n","            loss.backward()\n","            # scaler.scale(loss).backward()\n","            if i % grad_acc == grad_acc - 1:\n","                torch.nn.utils.clip_grad_norm_(params, 0.5)\n","                optimizer.step()\n","                # scaler.step(optimizer)\n","                # scaler.update()\n","                scheduler.step()\n","                ema.update()\n","                bar.update()\n","                optimizer.zero_grad()\n","                if global_i % save_every == save_every - 1:\n","                    os.makedirs(\"checkpoints\", exist_ok=True)\n","                    filename = f\"checkpoints/{global_i:06}.ckpt\"\n","                    if save_verbose:\n","                        torch.save(dict(\n","                            iter=global_i + 1,\n","                            model=get_sd(),\n","                            optimizer=optimizer.state_dict()), filename)\n","                    else:\n","                        with ema.average_parameters():\n","                            torch.save(dict(\n","                                iter=global_i + 1,\n","                                model=get_sd()), filename)\n","                    shutil.copy(filename, \"checkpoints/last.ckpt\")\n","                if global_i % generate_every == generate_every - 1:\n","                    print(f\"Generating step {global_i + 1}...\")\n","                    with torch.inference_mode(), torch.autocast(\"cuda\"):\n","                        model.eval()\n","                        out = Output()\n","                        display(out)\n","                        with ema.average_parameters():\n","                            for i, (x, y) in zip(range(n_generate), test_dl):\n","                                with out:\n","                                    print(\"Prompt:\", x[0])\n","                                    display(pipe(x[0])[\"sample\"][0])\n","                global_i += 1\n","                if global_i >= train_steps:\n","                    break\n","        if global_i >= train_steps:\n","            break\n","except KeyboardInterrupt:\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"Oiy__jcgvV4_"},"outputs":[],"source":["#@markdown Plot loss graph\n","# from inspect import getsource\n","# print(getsource(pipe.__call__))\n","from matplotlib import pyplot as plt\n","plt.plot(losses)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"4dOcPXE0LxJB"},"source":["### Load checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WiIVz_E_LyU1"},"outputs":[],"source":["import traceback\n","\n","\n","checkpoint_path = \"checkpoints/last.ckpt\"  #@param {type: \"string\", allow-input: true}  [\"\", \"checkpoints/last.ckpt\"]\n","try:\n","    dct = torch.load(checkpoint_path)\n","    global_i = dct[\"iter\"]\n","    model.load_state_dict(dct[\"model\"], strict=False)\n","    if \"optimizer\" in dct:\n","        optimizer.load_state_dict(dct[\"optimizer\"])\n","except FileNotFoundError:\n","    pass\n","except:\n","    traceback.print_exc()"]},{"cell_type":"markdown","metadata":{"id":"3NXFFfjsS-zj"},"source":["### Generate images from the fine-tuned model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yEErJFjlrSWS"},"outputs":[],"source":["from more_itertools import chunked\n","\n","\n","def image_grid(imgs, rows, cols):\n","    # assert len(imgs) == rows*cols\n","\n","    w, h = imgs[0].size\n","    grid = Image.new(\"RGB\", size=(cols*w, rows*h))\n","    grid_w, grid_h = grid.size\n","    \n","    for i, img in enumerate(imgs):\n","        grid.paste(img, box=(i%cols*w, i//cols*h))\n","    return grid\n","\n","\n","prompt = \"A man with a hat,\"  #@param {type: \"string\"}\n","num_images = 1  #@param {type: \"integer\"}\n","cols = 3  #@param {type: \"integer\"}\n","use_ema = False  #@param {type: \"boolean\"}\n","bs = 1  # TODO\n","images = []\n","with torch.autocast(\"cuda\"), torch.inference_mode(), (\n","    ema.average_parameters() if use_ema else open(\"/tmp/ihopethisfiledoesntactuallyexist\", \"w\")):\n","    for i in tqdm(list(chunked([prompt] * num_images, bs))):\n","        images += pipe(i)[\"sample\"]\n","image_grid(images, (num_images - 1) // cols + 1, cols)"]},{"cell_type":"markdown","metadata":{"id":"_VZ6LtdJk8_-"},"source":["### Save to Huggingface Hub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"quoNKnDFly59"},"outputs":[],"source":["#@title Save config\n","import json\n","config = {k: v for k, v in globals().items() if k in [\"train_bs\", \"test_bs\", \"train_steps\", \"warmup\", \"grad_acc\", \"lr\", \"wd\", \"ema_decay\", \"scheduler_type\", \"to_tune\"]}\n","json.dump(config, open(\"config.json\", \"w\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"Um6kJUmIlDaC"},"outputs":[],"source":["#@title Write model (empty name to skip)\n","#@markdown Requires a token with write access. Paste your model path from hugging face here. E.g. username/modelname\n","model_path = \"\"  #@param {type:\"string\"}\n","\n","if True:\n","    from huggingface_hub import HfApi, HfFolder, create_repo\n","    from huggingface_hub.utils import HfHubHTTPError\n","    try:\n","        create_repo(model_path, private=True, repo_type=\"model\")\n","    except HfHubHTTPError:\n","        pass\n","    api = HfApi()\n","    api.upload_file(\n","        path_or_fileobj=\"config.json\",\n","        path_in_repo=\"conf.json\",\n","        repo_id=model_path,\n","    )\n","    api.upload_file(\n","        path_or_fileobj=\"checkpoints/last.ckpt\",\n","        path_in_repo=\"checkpoint.ckpt\",\n","        repo_id=model_path,\n","    )"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["3NXFFfjsS-zj"],"provenance":[{"file_id":"1dQaqXFtHaRIf_8ahfiKKArTovUMFaLua","timestamp":1667220825579},{"file_id":"1vrh_MUSaAMaC5tsLWDxkFILKJ790Z4Bl","timestamp":1666107835736},{"file_id":"1m83eHWxGjhAdERqwy_8HwXmyY_H38Lw1","timestamp":1665472867479},{"file_id":"1jYZIbYSmEGWClWuVYFyUR8nUKwW-c91x","timestamp":1665118204758},{"file_id":"1kLcUs50uo-vTQ3GFnbOpTHEt-wChnXNq","timestamp":1661717719940},{"file_id":"https://github.com/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb","timestamp":1661455068313}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"}}},"nbformat":4,"nbformat_minor":0}
