[captioning]
# Directory to search for images
directory =
# Sets the depth to travel into folders, default is a full walk through the root directory: 1, 2, 3
depth =
# Sets the write mode to use when and existing caption file exists, write, prepend, append
mode = write
# Skip processing or creating a caption if the caption files already exist
skip_existing = False
# Extension to use for tthe caption files: txt, caption
ext = txt
# Enable accelerate="auto" this can help balance across the GPU/vRAM/CPU/RAM (Some models do not support accelerate e.g. BLIP1)
use_accelerate = False
# Switches to CPU only, can be slow but allows you to use RAM for larger models
cpu_offload = False
# Model to use for captioning
model =
# Manually select either a Hugging Face model or file path
hf_override =
# Model to use for image classification CLIP/Zero Shot Category
clip_model =
# File containing clip categories for image classification
clip_cat =
# Categories with a score less than the set confidence level won't be included in final text output
clip_confidence = 0.65
# The maximum number of tokens for the caption model
max_tokens = 25
# The minimum number of tokens for the caption model (Ignored with pipeline method)
min_tokens = 8
# How many images to run in a batch, default is 1
batch_count = 1
# Use pipeline method for the caption model
use_pipeline = False
# Set 4 or 8 bit loading for captioning to help reduce vram usage (not supported in pipeline or cpu-offload): 4bit or 8bit
xbits =
# Suppresses some noise from the caption output
quiet = False